{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Page0526/Pytorch-crash-course/blob/main/deep-neural-networks/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc7a67df",
      "metadata": {
        "id": "bc7a67df"
      },
      "source": [
        "# A Simple AutoEncoder and Latent Space Visualization with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ý tưởng của AutoEncoder là encode input dưới latent space xong đó decode ra output (reconstructed image) gần giống với input. Ở đấy input sẽ được encoder như 1 điểm duy nhất (khác với VAE encode input as a distribution)"
      ],
      "metadata": {
        "id": "Ld5DLAPGbSGs"
      },
      "id": "Ld5DLAPGbSGs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminaries"
      ],
      "metadata": {
        "id": "bZ5oWa89GOy7"
      },
      "id": "bZ5oWa89GOy7"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "yJ7KYjqLdxik",
        "outputId": "b445945a-cd69-4152-fd0b-48b0a18ba25a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yJ7KYjqLdxik",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.0->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.0->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1525c069",
      "metadata": {
        "id": "1525c069",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# torchsummary for easy checking and debugging\n",
        "from torchsummary import summary\n",
        "# torchvision for downloading and processing data\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# Other for notebook UI and latent space visualization\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if CUDA is available on current machine\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Deivce: {DEVICE}')\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 3\n",
        "lr = 5e-4"
      ],
      "metadata": {
        "id": "LBRJS8HOdB8n",
        "outputId": "c6919a0e-c8a6-4c27-a024-95fc2372fa29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LBRJS8HOdB8n",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deivce: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c87956ce",
      "metadata": {
        "id": "c87956ce"
      },
      "source": [
        "## Loading FashionMNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  '''\n",
        "  Convert datasets from PIL Image to torch tensor, and padding 2 pixels on each side\n",
        "  '''\n",
        "  process = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Pad([2])\n",
        "  ])\n",
        "  # x - images, process each images in the batch\n",
        "  x = [process(data[0]) for data in batch]\n",
        "  # torch.concat(tensors, dim=0,*,out=None): concatenates given seq tensors (List of Tensors) in the given dim\n",
        "  '''\n",
        "  Eg:\n",
        "    x = torch.rand(2, 3):\n",
        "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
        "          [-0.1034, -0.5790,  0.1497]])\n",
        "    x = torch.concat((x, x, x), dim=0)\n",
        "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
        "          [-0.1034, -0.5790,  0.1497],\n",
        "          [ 0.6580, -1.0969, -0.4614],\n",
        "          [-0.1034, -0.5790,  0.1497],\n",
        "          [ 0.6580, -1.0969, -0.4614],\n",
        "          [-0.1034, -0.5790,  0.1497]])\n",
        "    x = torch.concat(x)\n",
        "    tensor([[ 0.6580, -1.0969, -0.4614],\n",
        "          [-0.1034, -0.5790,  0.1497],\n",
        "          [ 0.6580, -1.0969, -0.4614],\n",
        "          [-0.1034, -0.5790,  0.1497]])\n",
        "  '''\n",
        "  x = torch.concat(x).unsqueeze(1)\n",
        "  # y - labels\n",
        "  y = torch.LongTensor([data[1] for data in batch])\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "LJunJtpgeIR6"
      },
      "id": "LJunJtpgeIR6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"T-shirt/top\",\n",
        "\t          \"Trouser\",\n",
        "\t          \"Pullover\",\n",
        "\t          \"Dress\",\n",
        "\t          \"Coat\",\n",
        "\t          \"Sandla\",\n",
        "\t          \"Shirt\",\n",
        "\t          \"Sneaker\",\n",
        "\t          \"Bag\",\n",
        "\t          \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "9_zTLjlImIBp"
      },
      "id": "9_zTLjlImIBp",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download/load datase\n",
        "train_data = FashionMNIST(\"./MNIST_DATA\",train=True, download=True)\n",
        "valid_data = FashionMNIST(\"./MNIST_DATA\",train=False, download=True)\n",
        "\n",
        "# put datasets into DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "pQNST75Kmnzz",
        "outputId": "0af4ab8b-62cf-46ce-9d1d-157adf46db08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "id": "pQNST75Kmnzz",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 14137142.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATA/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 282050.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATA/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 4895231.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATA/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 7137942.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_DATA/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_DATA/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'collate_fn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-05d1324623b9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# put datasets into DataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mvalid_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'collate_fn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize data\n",
        "for _, data in enumerate(train_loader):\n",
        "  print()"
      ],
      "metadata": {
        "id": "kPdozU39mpo0"
      },
      "id": "kPdozU39mpo0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SvA3YOnCmpdn"
      },
      "id": "SvA3YOnCmpdn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O24g40jOmpQ8"
      },
      "id": "O24g40jOmpQ8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eha_TEvpmo5m"
      },
      "id": "Eha_TEvpmo5m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phVis4A3mos8"
      },
      "id": "phVis4A3mos8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_GTdz4vmoX-"
      },
      "id": "N_GTdz4vmoX-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TpG36XjrmoGY"
      },
      "id": "TpG36XjrmoGY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2aa08e2a",
      "metadata": {
        "id": "2aa08e2a"
      },
      "source": [
        "## AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f76057d0",
      "metadata": {
        "id": "f76057d0"
      },
      "source": [
        "Here we implement a mirrored encoder-decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c6bc57",
      "metadata": {
        "id": "43c6bc57"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30889ce1",
      "metadata": {
        "id": "30889ce1"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d0ac270",
      "metadata": {
        "id": "7d0ac270"
      },
      "source": [
        "### AutoEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56d2731a",
      "metadata": {
        "id": "56d2731a"
      },
      "source": [
        "## Experiment"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "47Dr-eXPHiaC"
      },
      "id": "47Dr-eXPHiaC",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}